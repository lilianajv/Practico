{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPu5eV8jOI+9vn2f/BMBWra",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lilianajv/Practico/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "esWvqS9Ttrpd"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, AveragePooling2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_train(path):\n",
        "  datagen = ImageDataGenerator(rescale=1.0/255, horizontal_flip=True, vertical_flip=True)\n",
        "  #train_datagen = ImageDataGenerator(validation_split=0.25, rescale=1.0/255)\n",
        "  #val_datagen = ImageDataGenerator(validation_split=0.25, rescale=1./255)\n",
        "  train_datagen_flow = datagen.flow_from_directory(path, target_size = (150, 150), class_mode='sparse', batch_size=16, seed=12345)\n",
        "  #val_datagen_flow = datagen.flow_from_directory(path, target_size = (150, 150), class_mode='sparse', batch_size=16, subset=\"validation\", seed=12345)\n",
        "  \n",
        "  return train_datagen_flow"
      ],
      "metadata": {
        "id": "E51tRJ2SuM-i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(input_shape=(150, 150, 3)):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(6,(5, 5),padding='same', activation=\"relu\", input_shape=input_shape))\n",
        "  model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "  model.add(Conv2D(filters=16, kernel_size=(5, 5), padding='valid', activation=\"relu\"))\n",
        "  model.add(AveragePooling2D(pool_size = (2, 2)))\n",
        "  model.add(Flatten())\n",
        "  #model.add(Dense(units=120, activation='relu'))\n",
        "  model.add(Dense(units=64, activation=\"relu\"))\n",
        "  model.add(Dense(units=12, activation=\"softmax\"))\n",
        "  optimizer = Adam(lr=0.0001)\n",
        "\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "ZWTPJvVxyehV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_data, test_data, batch_size=None, epochs=6, steps_per_epoch=None, validation_steps=None):\n",
        "  #model.fit(train_data, validation_data=test_data, batch_size=batch_size, epochs=epochs, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps, verbose=2) \n",
        "  if steps_per_epoch is None:\n",
        "    steps_per_epoch = len(train_data)\n",
        "  if validation_steps is None:\n",
        "    validation_steps = len(test_data) \n",
        "  model.fit(train_data, validation_data=test_data, batch_size=batch_size, epochs=epochs, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps, verbose=2)\n",
        "  return model"
      ],
      "metadata": {
        "id": "aziwvJWh1IfU"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}